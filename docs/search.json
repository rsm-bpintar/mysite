[
  {
    "objectID": "resume.html",
    "href": "resume.html",
    "title": "Brian‚Äôs Resume",
    "section": "",
    "text": "Last updated 8/24/24\nDownload PDF file."
  },
  {
    "objectID": "projects/hw1/index.html",
    "href": "projects/hw1/index.html",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nPublished in 2007, this experiment was inspired by America‚Äôs significant increase in private charitable giving in the decades prior. It was alluded to the fact that a combination of increased wealth and an aging population in America likely caused this increase. Their analysis originally concluded that the match offer increases both the revenue per solicitation and the response rate. However, larger match ratios (i.e., $3:$1 instead of $1:$1) did not have any additional impact. It was also concluded that the matching had a much larger effect in red states than blue states.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/hw1/index.html#introduction",
    "href": "projects/hw1/index.html#introduction",
    "title": "A Replication of Karlan and List (2007)",
    "section": "",
    "text": "Dean Karlan at Yale and John List at the University of Chicago conducted a field experiment to test the effectiveness of different fundraising letters. They sent out 50,000 fundraising letters to potential donors, randomly assigning each letter to one of three treatments: a standard letter, a matching grant letter, or a challenge grant letter. They published the results of this experiment in the American Economic Review in 2007. The article and supporting data are available from the AEA website and from Innovations for Poverty Action as part of Harvard‚Äôs Dataverse.\nPublished in 2007, this experiment was inspired by America‚Äôs significant increase in private charitable giving in the decades prior. It was alluded to the fact that a combination of increased wealth and an aging population in America likely caused this increase. Their analysis originally concluded that the match offer increases both the revenue per solicitation and the response rate. However, larger match ratios (i.e., $3:$1 instead of $1:$1) did not have any additional impact. It was also concluded that the matching had a much larger effect in red states than blue states.\nThis project seeks to replicate their results."
  },
  {
    "objectID": "projects/hw1/index.html#data",
    "href": "projects/hw1/index.html#data",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Data",
    "text": "Data\n\nDescription\n\nimport pandas as pd\ndf = pd.read_stata('karlan_list_2007.dta')\ndf.head()\n\n\n\n\n\n\n\n\ntreatment\ncontrol\nratio\nratio2\nratio3\nsize\nsize25\nsize50\nsize100\nsizeno\n...\nredcty\nbluecty\npwhite\npblack\npage18_39\nave_hh_sz\nmedian_hhincome\npowner\npsch_atlstba\npop_propurban\n\n\n\n\n0\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n0.0\n1.0\n0.446493\n0.527769\n0.317591\n2.10\n28517.0\n0.499807\n0.324528\n1.0\n\n\n1\n0\n1\nControl\n0\n0\nControl\n0\n0\n0\n0\n...\n1.0\n0.0\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\nNaN\n\n\n2\n1\n0\n1\n0\n0\n$100,000\n0\n0\n1\n0\n...\n0.0\n1.0\n0.935706\n0.011948\n0.276128\n2.48\n51175.0\n0.721941\n0.192668\n1.0\n\n\n3\n1\n0\n1\n0\n0\nUnstated\n0\n0\n0\n1\n...\n1.0\n0.0\n0.888331\n0.010760\n0.279412\n2.65\n79269.0\n0.920431\n0.412142\n1.0\n\n\n4\n1\n0\n1\n0\n0\n$50,000\n0\n1\n0\n0\n...\n0.0\n1.0\n0.759014\n0.127421\n0.442389\n1.85\n40908.0\n0.416072\n0.439965\n1.0\n\n\n\n\n5 rows √ó 51 columns\n\n\n\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n\n\n\n\n\n\n\nVariable\nDescription\n\n\n\n\ntreatment\nTreatment\n\n\ncontrol\nControl\n\n\nratio\nMatch ratio\n\n\nratio2\n2:1 match ratio\n\n\nratio3\n3:1 match ratio\n\n\nsize\nMatch threshold\n\n\nsize25\n$25,000 match threshold\n\n\nsize50\n$50,000 match threshold\n\n\nsize100\n$100,000 match threshold\n\n\nsizeno\nUnstated match threshold\n\n\nask\nSuggested donation amount\n\n\naskd1\nSuggested donation was highest previous contribution\n\n\naskd2\nSuggested donation was 1.25 x highest previous contribution\n\n\naskd3\nSuggested donation was 1.50 x highest previous contribution\n\n\nask1\nHighest previous contribution (for suggestion)\n\n\nask2\n1.25 x highest previous contribution (for suggestion)\n\n\nask3\n1.50 x highest previous contribution (for suggestion)\n\n\namount\nDollars given\n\n\ngave\nGave anything\n\n\namountchange\nChange in amount given\n\n\nhpa\nHighest previous contribution\n\n\nltmedmra\nSmall prior donor: last gift was less than median $35\n\n\nfreq\nNumber of prior donations\n\n\nyears\nNumber of years since initial donation\n\n\nyear5\nAt least 5 years since initial donation\n\n\nmrm2\nNumber of months since last donation\n\n\ndormant\nAlready donated in 2005\n\n\nfemale\nFemale\n\n\ncouple\nCouple\n\n\nstate50one\nState tag: 1 for one observation of each of 50 states; 0 otherwise\n\n\nnonlit\nNonlitigation\n\n\ncases\nCourt cases from state in 2004-5 in which organization was involved\n\n\nstatecnt\nPercent of sample from state\n\n\nstateresponse\nProportion of sample from the state who gave\n\n\nstateresponset\nProportion of treated sample from the state who gave\n\n\nstateresponsec\nProportion of control sample from the state who gave\n\n\nstateresponsetminc\nstateresponset - stateresponsec\n\n\nperbush\nState vote share for Bush\n\n\nclose25\nState vote share for Bush between 47.5% and 52.5%\n\n\nred0\nRed state\n\n\nblue0\nBlue state\n\n\nredcty\nRed county\n\n\nbluecty\nBlue county\n\n\npwhite\nProportion white within zip code\n\n\npblack\nProportion black within zip code\n\n\npage18_39\nProportion age 18-39 within zip code\n\n\nave_hh_sz\nAverage household size within zip code\n\n\nmedian_hhincome\nMedian household income within zip code\n\n\npowner\nProportion house owner within zip code\n\n\npsch_atlstba\nProportion who finished college within zip code\n\n\npop_propurban\nProportion of population urban within zip code\n\n\n\n\n\n\n\n\nBalance Test\nAs an ad hoc test of the randomization mechanism, I provide a series of tests that compare aspects of the treatment and control groups to assess whether they are statistically significantly different from one another.\n\nimport numpy as np\nfrom scipy.stats import t\n\ndef t_test_randomization_check(df, column, treat_col='treatment', control_col='control'):\n    \"\"\"\n    Performs Welch's t-test to compare treatment and control groups for a given variable.\n\n    Parameters:\n    - df: pandas DataFrame\n    - column: name of the column to compare (e.g., 'mrm2')\n    - treat_col: name of the treatment indicator column (default: 'treatment')\n    - control_col: name of the control indicator column (default: 'control')\n    \"\"\"\n\n    # Extract the groups\n    treat = df[df[treat_col] == 1][column].dropna()\n    control = df[df[control_col] == 1][column].dropna()\n\n    # Means and standard deviations\n    mean_treat = treat.mean()\n    mean_control = control.mean()\n    std_treat = treat.std(ddof=1)\n    std_control = control.std(ddof=1)\n\n    # Sample sizes\n    n_treat = len(treat)\n    n_control = len(control)\n\n    # t-statistic\n    numerator = mean_treat - mean_control\n    denominator = np.sqrt((std_treat**2)/n_treat + (std_control**2)/n_control)\n    t_stat = numerator / denominator\n\n    # Degrees of freedom (Welch-Satterthwaite)\n    var_treat = std_treat**2 / n_treat\n    var_control = std_control**2 / n_control\n    df_numerator = (var_treat + var_control)**2\n    df_denominator = (var_treat**2 / (n_treat - 1)) + (var_control**2 / (n_control - 1))\n    df_welch = df_numerator / df_denominator\n\n    # p-value\n    p_value = 2 * (1 - t.cdf(np.abs(t_stat), df=df_welch))\n\n    # Output\n    print(f\"\\nüß™ T-Test for '{column}': Treatment vs Control\")\n    print(f\"Treatment mean: {mean_treat:.2f}; Control mean: {mean_control:.2f}\")\n    print(f\"Treatment std dev: {std_treat:.2f}; Control std dev: {std_control:.2f}\")\n    print(f\"t-statistic: {t_stat:.4f}\")\n    print(f\"Degrees of freedom: {df_welch:.2f}\")\n    print(f\"p-value: {p_value:.4f}\")\n\n    # Decision\n    if p_value &lt; 0.05:\n        print(\"‚ùó Reject the null hypothesis: The groups are significantly different.\")\n    else:\n        print(\"‚úÖ Fail to reject the null hypothesis: No significant difference between groups.\")\n\n\nt_test_randomization_check(df, 'mrm2')\nt_test_randomization_check(df, 'female')\nt_test_randomization_check(df, 'red0')\n\n\nüß™ T-Test for 'mrm2': Treatment vs Control\nTreatment mean: 13.01; Control mean: 13.00\nTreatment std dev: 12.09; Control std dev: 12.07\nt-statistic: 0.1195\nDegrees of freedom: 33394.48\np-value: 0.9049\n‚úÖ Fail to reject the null hypothesis: No significant difference between groups.\n\nüß™ T-Test for 'female': Treatment vs Control\nTreatment mean: 0.28; Control mean: 0.28\nTreatment std dev: 0.45; Control std dev: 0.45\nt-statistic: -1.7535\nDegrees of freedom: 32450.81\np-value: 0.0795\n‚úÖ Fail to reject the null hypothesis: No significant difference between groups.\n\nüß™ T-Test for 'red0': Treatment vs Control\nTreatment mean: 0.41; Control mean: 0.40\nTreatment std dev: 0.49; Control std dev: 0.49\nt-statistic: 1.8773\nDegrees of freedom: 33450.52\np-value: 0.0605\n‚úÖ Fail to reject the null hypothesis: No significant difference between groups.\n\n\nThe above results confirm randomization of the experiment. There was no significant difference in the treatment and control groups regarding the number of months since last donation, the percentage of male/female participants, or participants in red/blue states, which could have affected the results. Let‚Äôs compare results with a linear regression for the months since last donation variable ‚Äòmrm2‚Äô to confirm our approach.\n\nimport statsmodels.api as sm\n\ndf_reg = df[['mrm2', 'treatment']].dropna()\n\n#define x and y\nX = df_reg['treatment']\nX = sm.add_constant(X)\ny = df_reg['mrm2']\n\n#fit model\nmodel = sm.OLS(y,X).fit()\n\n#extract values\ncoef = model.params['treatment']\nt_stat = model.tvalues['treatment']\np_value = model.pvalues['treatment']\n\nprint(f\"Coefficient (treatment): {coef:.4f}\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\nCoefficient (treatment): 0.0137\nt-statistic: 0.1195\np-value: 0.9049\n\n\nThe t-statistics and p-values match accordingly, confirming the method.\nTable 1 is included in the original report to provide evidence of randomization of the treatment and control groups. This is proven to be true, being that we fail to reject the null hypothesis with no statistically significant difference in demographics for treatment and control groups."
  },
  {
    "objectID": "projects/hw1/index.html#experimental-results",
    "href": "projects/hw1/index.html#experimental-results",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Experimental Results",
    "text": "Experimental Results\n\nCharitable Contribution Made\nFirst, I analyze whether matched donations lead to an increased response rate of making a donation.\n\nimport matplotlib.pyplot as plt\n\n#calculate proportions\nprop_treatment = df[df['treatment'] == 1]['gave'].mean()\nprop_control = df[df['control'] == 1]['gave'].mean()\n\n#data for plot\ngroups = ['Treatment', 'Control']\nproportions = [prop_treatment, prop_control]\n\n#plot\nplt.figure(figsize=(6,4))\nplt.bar(groups, proportions)\nplt.ylabel('Proportion Donated')\nplt.title('Donation Rate by Group')\nplt.ylim(0,.05)\nplt.show()\n\n\n\n\n\n\n\n\nBased on the bar chart above, it appears that the treatment had a slight effect on donation rates.\n\ndf_lpm = df[['gave', 'treatment']].dropna()\n\n#define outcome and predictor\nX = sm.add_constant(df_lpm['treatment'])\ny = df_lpm['gave']\n\n#fit linear regression\nmodel = sm.OLS(y, X).fit()\n\n#extract stats\ncoef = model.params['treatment']\nt_stat = model.tvalues['treatment']\np_value = model.pvalues['treatment']\n\n#output\nprint(f\"Coefficient (treatment effect): {coef:.4f}\")\nprint(f\"t-statistic: {t_stat:.4f}\")\nprint(f\"p-value: {p_value:.4f}\")\n\nCoefficient (treatment effect): 0.0042\nt-statistic: 3.1014\np-value: 0.0019\n\n\nWhile the effect is small, it is statistically significant based on the p-value of less than .05. This implies that people in general provided donations more when told that donations would be matched.\n\ndf_probit = df[['gave', 'treatment']].dropna()\n\n#define predictors and outcome\nX = sm.add_constant(df_probit['treatment'])\ny = df_probit['gave']\n\n#fit probit model\nprobit_model = sm.Probit(y, X).fit()\n\nmfx = probit_model.get_margeff()\nprint(mfx.summary())\n\nOptimization terminated successfully.\n         Current function value: 0.100443\n         Iterations 7\n       Probit Marginal Effects       \n=====================================\nDep. Variable:                   gave\nMethod:                          dydx\nAt:                           overall\n==============================================================================\n                dy/dx    std err          z      P&gt;|z|      [0.025      0.975]\n------------------------------------------------------------------------------\ntreatment      0.0043      0.001      3.104      0.002       0.002       0.007\n==============================================================================\n\n\nThe probit regression indicates an increase in probability of donating by 0.43%, holding all else constant, when given the treatment (matching). This is consistent with the linear regression results, as effect is small. P-values also match, and are statistically significant. Treatment has a statistically significant but modest positive effect on probability of donation.\nNOTE: Linear regression results appear replicate Table 3 column 1 in the paper. Probit results do not, despite Table 3 indicating its results come from probit regressions‚Ä¶\n\n\nDifferences between Match Rates\nNext, I assess the effectiveness of different sizes of matched donations on the response rate.\n\ndef t_test_donation_rate(df, ratio_a, ratio_b, outcome_col='gave', ratio_col='ratio'):\n    \"\"\"\n    Performs and prints a Welch's t-test comparing donation rates between two match ratio groups.\n    \n    Parameters:\n    - df: pandas DataFrame\n    - ratio_a: first ratio value (e.g., 1, 2, 3, or \"Control\")\n    - ratio_b: second ratio value\n    - outcome_col: name of the binary outcome column (default: 'gave')\n    - ratio_col: name of the match ratio column (default: 'ratio')\n    \n    Returns:\n    - Dictionary of test results\n    \"\"\"\n    \n    group_a = df[df[ratio_col] == ratio_a][outcome_col].dropna()\n    group_b = df[df[ratio_col] == ratio_b][outcome_col].dropna()\n\n    n1, n2 = len(group_a), len(group_b)\n    p1, p2 = group_a.mean(), group_b.mean()\n\n    # Standard error\n    se = np.sqrt((p1 * (1 - p1)) / n1 + (p2 * (1 - p2)) / n2)\n\n    # t-statistic\n    t_stat = (p2 - p1) / se\n\n    # Degrees of freedom\n    var1 = (p1 * (1 - p1)) / n1\n    var2 = (p2 * (1 - p2)) / n2\n    df_welch = (var1 + var2)**2 / ((var1**2)/(n1 - 1) + (var2**2)/(n2 - 1))\n\n    # Two-tailed p-value\n    p_value = 2 * (1 - t.cdf(np.abs(t_stat), df=df_welch))\n\n    # Print results\n    print(f\"\\nüéØ T-Test: {ratio_b}:1 vs {ratio_a}:1 Match Ratio\")\n    print(\"-\" * 40)\n    print(f\"Sample size ({ratio_a}:1): {n1}\")\n    print(f\"Sample size ({ratio_b}:1): {n2}\")\n    print(f\"Donation rate ({ratio_a}:1): {p1:.4f}\")\n    print(f\"Donation rate ({ratio_b}:1): {p2:.4f}\")\n    print(f\"t-statistic: {t_stat:.4f}\")\n    print(f\"Degrees of freedom: {df_welch:.2f}\")\n    print(f\"p-value: {p_value:.4f}\")\n    \n    if p_value &lt; 0.05:\n        print(\"‚úÖ Statistically significant at the 5% level.\")\n    else:\n        print(\"‚ùå Not statistically significant at the 5% level.\")\n\nt_test_donation_rate(df, 1, 2)  # 1:1 vs 2:1\nt_test_donation_rate(df, 2, 3)\nt_test_donation_rate(df, 1, 3)\n\n\nüéØ T-Test: 2:1 vs 1:1 Match Ratio\n----------------------------------------\nSample size (1:1): 11133\nSample size (2:1): 11134\nDonation rate (1:1): 0.0207\nDonation rate (2:1): 0.0226\nt-statistic: 0.9651\nDegrees of freedom: 22225.08\np-value: 0.3345\n‚ùå Not statistically significant at the 5% level.\n\nüéØ T-Test: 3:1 vs 2:1 Match Ratio\n----------------------------------------\nSample size (2:1): 11134\nSample size (3:1): 11129\nDonation rate (2:1): 0.0226\nDonation rate (3:1): 0.0227\nt-statistic: 0.0501\nDegrees of freedom: 22260.85\np-value: 0.9600\n‚ùå Not statistically significant at the 5% level.\n\nüéØ T-Test: 3:1 vs 1:1 Match Ratio\n----------------------------------------\nSample size (1:1): 11133\nSample size (3:1): 11129\nDonation rate (1:1): 0.0207\nDonation rate (3:1): 0.0227\nt-statistic: 1.0151\nDegrees of freedom: 22215.05\np-value: 0.3101\n‚ùå Not statistically significant at the 5% level.\n\n\nAuthor suggests that neither the different match thresholds or example amount had a meaningful influence on behavior. Results above suggest the same. Not enough evidence to conclude that the difference in donation rates is statistically significant for different treatment options.\nCreate the ratio1 variable.\n\n#create the ratio1 variable\ndf['ratio_str'] = df['ratio'].astype('str')\ndf['ratio1'] = (df['ratio_str'] == '1').astype(int)\ndf['ratio2'] = (df['ratio_str'] == '2').astype(int)\ndf['ratio3'] = (df['ratio_str'] == '3').astype(int)\nprint(df[['ratio', 'ratio1', 'ratio2', 'ratio3']].head(10))\n\n     ratio  ratio1  ratio2  ratio3\n0  Control       0       0       0\n1  Control       0       0       0\n2        1       1       0       0\n3        1       1       0       0\n4        1       1       0       0\n5  Control       0       0       0\n6        1       1       0       0\n7        2       0       1       0\n8        2       0       1       0\n9        1       1       0       0\n\n\nRegression results are presented below.\n\ndef compare_match_ratios(df, ratio_a, ratio_b, ratio_col='ratio', outcome_col='gave'):\n    \"\"\"\n    Compare two match ratios using linear regression on a binary outcome.\n\n    Parameters:\n    - df: DataFrame with data\n    - ratio_a: first match ratio to compare (e.g., 1 for 1:1)\n    - ratio_b: second match ratio to compare (e.g., 2 for 2:1)\n    - ratio_col: name of the column containing match ratios\n    - outcome_col: name of the binary outcome column\n\n    Returns:\n    - Dictionary with coefficient and p-value\n    \"\"\"\n\n    # Filter to only the two groups being compared\n    df_sub = df[df[ratio_col].isin([ratio_a, ratio_b])].copy()\n\n    # Create indicator for being in ratio_b group\n    df_sub['is_ratio_b'] = (df_sub[ratio_col] == ratio_b).astype(int)\n\n    # Run regression\n    X = sm.add_constant(df_sub['is_ratio_b'])\n    y = df_sub[outcome_col]\n\n    model = sm.OLS(y, X).fit()\n\n    coef = model.params['is_ratio_b']\n    p_value = model.pvalues['is_ratio_b']\n\n    print(f\"\\nüìä Comparing donation rates: {ratio_b}:1 vs {ratio_a}:1\")\n    print(f\"Coefficient (diff in donation rate): {coef:.4f}\")\n    print(f\"p-value: {p_value:.4f}\")\n\ncompare_match_ratios(df, 1, 2)  # Compare 2:1 vs 1:1\ncompare_match_ratios(df, 2, 3)\ncompare_match_ratios(df, 1, 3) \n\n\nüìä Comparing donation rates: 2:1 vs 1:1\nCoefficient (diff in donation rate): 0.0019\np-value: 0.3345\n\nüìä Comparing donation rates: 3:1 vs 2:1\nCoefficient (diff in donation rate): 0.0001\np-value: 0.9600\n\nüìä Comparing donation rates: 3:1 vs 1:1\nCoefficient (diff in donation rate): 0.0020\np-value: 0.3101\n\n\nThe regression results above indicate the same. The differences between donation rates of the different match ratios are not statistically significant, and therefore do not indicate any effect.\n\n# Response (donation) rates\np_1 = df[df['ratio'] == 1]['gave'].mean()\np_2 = df[df['ratio'] == 2]['gave'].mean()\np_3 = df[df['ratio'] == 3]['gave'].mean()\n\n# Differences in raw proportions\ndiff_2v1 = p_2 - p_1\ndiff_3v2 = p_3 - p_2\ndiff_3v1 = p_3 - p_1\n\nprint(f\"Direct from data:\")\nprint(f\"2:1 vs 1:1: {diff_2v1:.4f}\")\nprint(f\"3:1 vs 2:1: {diff_3v2:.4f}\")\nprint(f\"3:1 vs 1:1: {diff_3v1:.4f}\")\n\nDirect from data:\n2:1 vs 1:1: 0.0019\n3:1 vs 2:1: 0.0001\n3:1 vs 1:1: 0.0020\n\n\nResults from data match the regression coefficients. We can safely conclude that there is no effect that match ratios have on donation rates.\n\n\nSize of Charitable Contribution\nIn this subsection, I analyze the effect of the size of matched donation on the size of the charitable contribution.\ntodo: Calculate a t-test or run a bivariate linear regression of the donation amount on the treatment status. What do we learn from doing this analysis?\n\ndf_reg = df[['amount', 'treatment']].dropna()\n\nX = sm.add_constant(df_reg['treatment'])\ny = df_reg['amount']\n\nmodel = sm.OLS(y, X).fit()\n\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\n\nprint(f\"Treatment effect (difference in donation amount): {coef:.4f}\")\nprint(f\"p-value: {pval:.4f}\")\n\nTreatment effect (difference in donation amount): 0.1536\np-value: 0.0628\n\n\nWhile the results from the regression analysis above indicate an increase of 0.15 in the donation amount when given the treatment letter, the p-value is not statistically significant at the 95% confidence level. However, the difference calculated is accurate compared to Table2A of original analysis.\n\n# Filter to donors only\ndf_donors = df[(df['amount'] &gt; 0) & df['treatment'].notna()][['amount', 'treatment']]\n\nX = sm.add_constant(df_donors['treatment'])\ny = df_donors['amount']\n\nmodel = sm.OLS(y, X).fit()\n\ncoef = model.params['treatment']\npval = model.pvalues['treatment']\n\nprint(f\"Treatment effect among donors: {coef:.2f}\")\nprint(f\"p-value: {pval:.4f}\")\n\nTreatment effect among donors: -1.67\np-value: 0.5615\n\n\nWhile the results of the above regression, only considering those who actually donated to begin with, indicate a small decrease in the donation amount, this amount is not statistically significant. Therefore, we cannot conclude that the treatment letters (those with the match ratios) have any significant causal effect on the actual donation amount.\n\n# Filter to donors only\ndf_donors = df[df['amount'] &gt; 0]\n\n# Split groups\ntreatment_amounts = df_donors[df_donors['treatment'] == 1]['amount']\ncontrol_amounts = df_donors[df_donors['control'] == 1]['amount']\n\n# Calculate means\nmean_treatment = treatment_amounts.mean()\nmean_control = control_amounts.mean()\n\n# Plot: Control Group\nplt.figure(figsize=(8, 5))\nplt.hist(control_amounts, bins=30, alpha=0.7, color='gray', edgecolor='black')\nplt.axvline(mean_control, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_control:.2f}')\nplt.title('Donation Amounts (Control Group)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Number of Donors')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n# Plot: Treatment Group\nplt.figure(figsize=(8, 5))\nplt.hist(treatment_amounts, bins=30, alpha=0.7, color='gray', edgecolor='black')\nplt.axvline(mean_treatment, color='red', linestyle='--', linewidth=2, label=f'Mean: ${mean_treatment:.2f}')\nplt.title('Donation Amounts (Treatment Group)')\nplt.xlabel('Donation Amount')\nplt.ylabel('Number of Donors')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe two histograms above indicate a similar average and similar distribution of donation amounts among those who donated to begin with."
  },
  {
    "objectID": "projects/hw1/index.html#simulation-experiment",
    "href": "projects/hw1/index.html#simulation-experiment",
    "title": "A Replication of Karlan and List (2007)",
    "section": "Simulation Experiment",
    "text": "Simulation Experiment\nAs a reminder of how the t-statistic ‚Äúworks,‚Äù in this section I use simulation to demonstrate the Law of Large Numbers and the Central Limit Theorem.\nSuppose the true distribution of respondents who do not get a charitable donation match is Bernoulli with probability p=0.018 that a donation is made.\nFurther suppose that the true distribution of respondents who do get a charitable donation match of any size is Bernoulli with probability p=0.022 that a donation is made.\n\nLaw of Large Numbers\n\n# Set random seed for reproducibility\nnp.random.seed(42)\n\n# Step 1: Simulate 10k Bernoulli draws for each group\nn_draws = 10000\ncontrol_draws = np.random.binomial(1, 0.018, size=n_draws)\ntreatment_draws = np.random.binomial(1, 0.022, size=n_draws)\n\n# Step 2: Compute the vector of differences\ndiffs = treatment_draws - control_draws  # element-wise difference\n\n# Step 3: Compute cumulative average of the differences\ncumulative_avg = np.cumsum(diffs) / np.arange(1, n_draws + 1)\n\n# Step 4: Plot cumulative average\nplt.figure(figsize=(10, 6))\nplt.plot(cumulative_avg, label='Cumulative Average Treatment Effect')\nplt.axhline(y=0.004, color='red', linestyle='--', label='True Difference (0.022 - 0.018)')\nplt.title('Cumulative Average of Simulated Treatment Effect')\nplt.xlabel('Number of Simulations')\nplt.ylabel('Cumulative Average Difference')\nplt.legend()\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nAccordingly, in the simulation above, the cumulative average eventually converges towards the true difference of 0.004. As the sample size of the random simulation gets larger, the average eventually converges to the true average.\n\n\nCentral Limit Theorem\n\n# Set seed\nnp.random.seed(42)\n\n# Parameters\np_control = 0.018\np_treatment = 0.022\nn_simulations = 1000\nsample_sizes = [50, 200, 500, 1000]\n\n# Create subplots\nfig, axes = plt.subplots(2, 2, figsize=(12, 10))\naxes = axes.flatten()\n\nfor i, n in enumerate(sample_sizes):\n    mean_diffs = []\n    \n    for _ in range(n_simulations):\n        # Sample from each distribution\n        control_sample = np.random.binomial(1, p_control, size=n)\n        treatment_sample = np.random.binomial(1, p_treatment, size=n)\n\n        # Calculate mean difference\n        diff = treatment_sample.mean() - control_sample.mean()\n        mean_diffs.append(diff)\n    \n    # Plot histogram\n    axes[i].hist(mean_diffs, bins=30, edgecolor='black', alpha=0.75)\n    axes[i].axvline(np.mean(mean_diffs), color='red', linestyle='--', linewidth=2, label=f'Mean: {np.mean(mean_diffs):.4f}')\n    axes[i].set_title(f'Sample Size = {n}')\n    axes[i].set_xlabel('Mean Difference')\n    axes[i].set_ylabel('Frequency')\n    axes[i].legend()\n    axes[i].grid(True)\n\n# Final layout\nplt.suptitle('Sampling Distribution of Mean Differences (Treatment - Control)', fontsize=16)\nplt.tight_layout(rect=[0, 0.03, 1, 0.95])\nplt.show()\n\n\n\n\n\n\n\n\nWhen running a simulation experiment, the sampling distribution takes on a bell-shape very quickly, even at sample size of 50, but gets smoothed out by the time sample size is 1000. Central Limit Theorem takes place earlier in the sequence than anticipated, approximating a normal distribution, but more filled in and smooth by 1000 sample size."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Brian Pintar",
    "section": "",
    "text": "This website is created for MGTA 495 assignments.\nThis is a Quarto website.\nTo learn more about Quarto websites visit https://quarto.org/docs/websites."
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "My Projects",
    "section": "",
    "text": "A Replication of Karlan and List (2007)\n\n\n\n\nBrian Pintar\nMay 4, 2025\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoisson Regression Examples\n\n\n\n\nBrian Pintar\nMay 4, 2025\n\n\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "projects/hw2/index.html",
    "href": "projects/hw2/index.html",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data. First, we can read in the data and do some exploratory analysis.\n\nimport pandas as pd\n\ndf1 = pd.read_csv('blueprinty.csv')\ndf1.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\nLet‚Äôs compare histograms and means of number of patents by customer status. todo: Compare histograms and means of number of patents by customer status. What do you observe?\n\nimport matplotlib.pyplot as plt\n\n# Create two histograms side by side\nplt.figure(figsize=(12, 5))\n\n# Histogram for non-customers\nplt.subplot(1, 2, 1)\nplt.hist(df1[df1['iscustomer'] == 0]['patents'], bins=30, alpha=0.7)\nplt.title('Non-Customers: Number of Patents')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\n# Histogram for customers\nplt.subplot(1, 2, 2)\nplt.hist(df1[df1['iscustomer'] == 1]['patents'], bins=30, alpha=0.7, color='orange')\nplt.title('Customers: Number of Patents')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nHistograms indicate somewhat similar results. Let‚Äôs compare means to test for statistical significance.\n\nfrom scipy.stats import ttest_ind\n\n# Separate the groups\npatents_customers = df1[df1['iscustomer'] == 1]['patents']\npatents_non_customers = df1[df1['iscustomer'] == 0]['patents']\n\n# Calculate means\nmean_customers = patents_customers.mean()\nmean_non_customers = patents_non_customers.mean()\n\n# Perform the t-test\nt_stat, p_value = ttest_ind(patents_customers, patents_non_customers, equal_var=False)\n\n# Print results\nprint(f\"Mean patents (customers): {mean_customers:.2f}\")\nprint(f\"Mean patents (non-customers): {mean_non_customers:.2f}\")\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_value:.3f}\")\n\nMean patents (customers): 4.13\nMean patents (non-customers): 3.47\nT-statistic: 4.873\nP-value: 0.000\n\n\nBased on our t-test results, we reject the null hypothesis that the means are equal.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\nLet‚Äôs compare age between the customer and non customer groups first.\n\nimport seaborn as sns\n\nplt.figure(figsize=(10, 5))\n\nsns.kdeplot(data=df1, x='age', hue='iscustomer', fill=True, common_norm=False, alpha=0.5)\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.legend(title='Is Customer', labels=['Non-Customer', 'Customer'])\nplt.show()\n\n\n\n\n\n\n\n\nThere appears to be a slight difference in age between customers and non customers. Let‚Äôs run a t-test to check.\n\n# Separate the age values\nage_customers = df1[df1['iscustomer'] == 1]['age']\nage_non_customers = df1[df1['iscustomer'] == 0]['age']\n\n# Calculate means\nmean_age_customers = age_customers.mean()\nmean_age_non_customers = age_non_customers.mean()\n\n# Perform the t-test\nt_stat_age, p_value_age = ttest_ind(age_customers, age_non_customers, equal_var=False)\n\n# Print results\nprint(f\"Mean age (customers): {mean_age_customers:.2f}\")\nprint(f\"Mean age (non-customers): {mean_age_non_customers:.2f}\")\nprint(f\"T-statistic (age): {t_stat_age:.3f}\")\nprint(f\"P-value (age): {p_value_age:.3f}\")\n\nMean age (customers): 26.90\nMean age (non-customers): 26.10\nT-statistic (age): 1.913\nP-value (age): 0.056\n\n\nWe fail to reject the null hypothesis, indicating no statistically significant difference in age between the customer and non customer groups. Now we repeat the process for region.\n\n# Create a count table (not normalized)\nregion_counts = pd.crosstab(df1['region'], df1['iscustomer'])\nregion_counts.columns = ['Non-Customers', 'Customers']\n\n# Plot grouped bar chart\nregion_counts.plot(kind='bar', figsize=(10, 6))\nplt.title('Number of Customers and Non-Customers by Region')\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.legend(title='Customer Status')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIt appears based on the chart that there are some differences in the proportions of customers vs.¬†non customers in different regions. We‚Äôll run a chi-squared test to check this.\n\nfrom scipy.stats import chi2_contingency\n\n# Crosstab: region vs customer status\nregion_table = pd.crosstab(df1['region'], df1['iscustomer'])\n\n# Chi-squared test\nchi2_stat, p_value_region, dof, expected = chi2_contingency(region_table)\n\nprint(\"Chi-squared Statistic:\", round(chi2_stat, 2))\nprint(\"Degrees of Freedom:\", dof)\nprint(\"P-value:\", round(p_value_region, 4))\n\nChi-squared Statistic: 233.63\nDegrees of Freedom: 4\nP-value: 0.0\n\n\nBased on the low p-value, we can assume there is a statistically significant relationship between region and customer status. Accordingly, the distribution of customers across regions is not random, as some are more or less likely to have customers.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nLet‚Äôs mathematically write the likelihood for_ \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nThe likelihood for all observations is:\n\\(L(\\lambda \\mid Y) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\\)\nThe log-likelihood is:\n\\(\\ell(\\lambda \\mid Y) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\\)\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example: Now let‚Äôs write the log-likelihood function for the Poisson model as a function of lambda and Y.\n\nimport numpy as np\nfrom scipy.special import gammaln  # log(Y!) = gammaln(Y + 1)\n\ndef poisson_loglikelihood(lambd, Y):\n    \"\"\"\n    Compute the log-likelihood of a Poisson model given lambda and observed data Y.\n\n    Parameters:\n    - lambd: float, the Poisson rate parameter (must be &gt; 0)\n    - Y: array-like, observed count data\n\n    Returns:\n    - log-likelihood value\n    \"\"\"\n    if lambd &lt;= 0:\n        return -np.inf  # log-likelihood is undefined for lambda &lt;= 0\n    return np.sum(-lambd + Y * np.log(lambd) - gammaln(Y + 1))\n\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\nNow, let‚Äôs use the function to plot lambda on the horizontal axis and the log-likelihood on the vertical axis for a range of lambdas.\n\n# Get observed patent data\nY_obs = df1['patents'].values\n\n# Define a range of lambda values to evaluate\nlambda_vals = np.linspace(0.1, 20, 200)\n\n# Compute the log-likelihood for each lambda\nloglik_vals = [poisson_loglikelihood(l, Y_obs) for l in lambda_vals]\n\n# Plot the log-likelihood curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, loglik_vals, color='blue', lw=2)\nplt.title('Log-Likelihood of Poisson Model vs. Lambda')\nplt.xlabel(r'$\\lambda$')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: If you‚Äôre feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which ‚Äúfeels right‚Äù because the mean of a Poisson distribution is lambda.\nWe start with the log-likelihood:\n\\[\n\\ell(\\lambda \\mid Y) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative:\n\\[\n\\frac{d\\ell}{d\\lambda} = \\sum_{i=1}^n \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^n Y_i\n\\]\nSet this equal to zero and solve:\n\\[\n-n + \\frac{1}{\\lambda} \\sum Y_i = 0 \\Rightarrow \\lambda = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\nTherefore, the MLE of \\(\\lambda\\) is the sample mean \\(\\bar{Y}\\).\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\nLet‚Äôs find the MLE by optimizing the likelihood function.\n\nfrom scipy.optimize import minimize_scalar\n\n# Reuse observed data\nY_obs = df1['patents'].values\n\n# Define negative log-likelihood function\ndef neg_loglik_poisson(lambd):\n    return -poisson_loglikelihood(lambd, Y_obs)\n\n# Use minimize_scalar to find the lambda that minimizes negative log-likelihood\nresult = minimize_scalar(neg_loglik_poisson, bounds=(0.01, 50), method='bounded')\n\n# Extract MLE\nlambda_mle_numerical = result.x\nloglik_at_mle = -result.fun\n\nprint(f\"MLE (Numerical): {lambda_mle_numerical:.4f}\")\nprint(f\"Log-Likelihood at MLE: {loglik_at_mle:.4f}\")\n\n# Compare to analytic MLE\nprint(f\"MLE (Analytic Mean): {np.mean(Y_obs):.4f}\")\n\nMLE (Numerical): 3.6847\nLog-Likelihood at MLE: -3367.6838\nMLE (Analytic Mean): 3.6847\n\n\nBoth methods agree that the best fitting Poisson model indicates that firms receive, on average, 3.68 patents every five years.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\nLet‚Äôs define our updated regression function.\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    \"\"\"\n    Log-likelihood for Poisson regression.\n\n    Parameters:\n    - beta: (p,) vector of coefficients\n    - Y: (n,) vector of observed counts\n    - X: (n, p) matrix of covariates\n\n    Returns:\n    - scalar log-likelihood value\n    \"\"\"\n    beta = np.asarray(beta, dtype=np.float64)  # ensure correct type\n    X = np.asarray(X, dtype=np.float64)        # ensure matrix format\n    Xb = np.dot(X, beta)                       # matrix multiplication\n    lambdas = np.exp(Xb)                       # element-wise exponential\n    return np.sum(-lambdas + Y * Xb - gammaln(Y + 1))\n\nNow, let‚Äôs create the covariate matrix X.\n\nimport patsy  # optional, but can simplify dummy creation\n\n# Create a copy of the data to work with\ndf = df1.copy()\n\n# Create new variables\n# Rescale age and age_squared\ndf['age'] = df['age'] / 10\ndf['age_squared'] = df['age'] ** 2\n\n# One-hot encode region, dropping one to avoid multicollinearity\nregion_dummies = pd.get_dummies(df['region'], drop_first=True)\n\n# Combine into one design matrix\nX = pd.concat([\n    pd.Series(1, index=df.index, name='intercept'),\n    df[['age', 'age_squared', 'iscustomer']],\n    pd.get_dummies(df['region'], drop_first=True)\n], axis=1)\n\nY = df['patents'].values\nX_mat = X.values  # for optimization input only\n\n# Column names\ncolumn_names = X.columns\n\ntodo: Use your function along with R‚Äôs optim() or Python‚Äôs sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1‚Äôs to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\nLet‚Äôs now optimize to find the MLE vector and the Hessian of the Poisson model with covariates.\n\nfrom scipy.optimize import minimize\n\nX_mat = X.to_numpy().astype(np.float64)  # make sure X is a NumPy array\nY_vec = Y.astype(np.float64)             # make sure Y is a NumPy array\ninit_beta = np.zeros(X_mat.shape[1])     # starting guess for beta (all 0s)\n\n# Define the negative log-likelihood function for use in optimizer\nneg_loglik = lambda b: -poisson_regression_loglikelihood(b, Y_vec, X_mat)\n\n# Optimize\nresult = minimize(neg_loglik, init_beta, method='BFGS')\n\nLet‚Äôs now extract the results.\n\n# Extract estimated coefficients and standard errors\nbeta_hat = result.x\nvcov_beta = result.hess_inv\nstandard_errors = np.sqrt(np.diag(vcov_beta))\n\n# Show results in a table\nsummary_table = pd.DataFrame({\n    'Coefficient': beta_hat,\n    'Std. Error': standard_errors\n}, index=X.columns)\n\nsummary_table\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.508925\n0.185670\n\n\nage\n1.486199\n0.139210\n\n\nage_squared\n-0.297048\n0.025840\n\n\niscustomer\n0.207591\n0.032190\n\n\nNortheast\n0.029170\n0.046083\n\n\nNorthwest\n-0.017574\n0.055659\n\n\nSouth\n0.056562\n0.054619\n\n\nSouthwest\n0.050576\n0.048116\n\n\n\n\n\n\n\nThe Poisson regression estimates how the expected number of patents awarded to a firm varies with its characteristics. To improve numerical stability during optimization, the age variable was scaled by a factor of 10 (i.e., a one-unit change in age represents a 10-year difference).\nThe coefficient for age is 1.49, and for age_squared is ‚àí0.30, indicating a non-linear relationship: as firms age, their expected number of patents initially increases, but the rate of increase slows and eventually declines with age.\nThe coefficient on iscustomer is 0.208, meaning that, holding all else equal, firms that use Blueprinty‚Äôs software have a 23% higher expected patent count compared to non-customers. See.\nRegional effects appear minimal, with all region dummy coefficients close to zero and standard errors indicating low statistical significance relative to the reference region.\ntodo: Check your results using R‚Äôs glm() function or Python sm.GLM() function.\nNow let‚Äôs compare results against the statsmodels ‚Äòsm.GLM()‚Äô function.\n\nimport statsmodels.api as sm\n\n# Recreate X_sm and ensure it's numeric\nX_sm = sm.add_constant(X.drop(columns='intercept'), has_constant='add')\nX_sm = X_sm.astype(float)  # &lt;== This line prevents the object dtype error\n\n# Also ensure Y is numeric\nY_numeric = Y.astype(float)\n\n# Fit GLM model\nglm_model = sm.GLM(Y_numeric, X_sm, family=sm.families.Poisson())\nglm_results = glm_model.fit()\n\n# Display summary\nprint(glm_results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Sun, 04 May 2025   Deviance:                       2143.3\nTime:                        16:43:58   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nconst          -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nage             1.4862      0.139     10.716      0.000       1.214       1.758\nage_squared    -0.2970      0.026    -11.513      0.000      -0.348      -0.246\niscustomer      0.2076      0.031      6.719      0.000       0.147       0.268\nNortheast       0.0292      0.044      0.669      0.504      -0.056       0.115\nNorthwest      -0.0176      0.054     -0.327      0.744      -0.123       0.088\nSouth           0.0566      0.053      1.074      0.283      -0.047       0.160\nSouthwest       0.0506      0.047      1.072      0.284      -0.042       0.143\n===============================================================================\n\n\ntodo: Interpret the results.\nThe results closely matched those from the custom maximum likelihood estimation (MLE) approach, with all coefficients and standard errors agreeing to several decimal places. This confirms that our manually coded log-likelihood function and optimization routine are correctly specified.\ntodo: What do you conclude about the effect of Blueprinty‚Äôs software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/hw2/index.html#blueprinty-case-study",
    "href": "projects/hw2/index.html#blueprinty-case-study",
    "title": "Poisson Regression Examples",
    "section": "",
    "text": "Blueprinty is a small firm that makes software for developing blueprints specifically for submitting patent applications to the US patent office. Their marketing team would like to make the claim that patent applicants using Blueprinty‚Äôs software are more successful in getting their patent applications approved. Ideal data to study such an effect might include the success rate of patent applications before using Blueprinty‚Äôs software and after using it. Unfortunately, such data is not available.\nHowever, Blueprinty has collected data on 1,500 mature (non-startup) engineering firms. The data include each firm‚Äôs number of patents awarded over the last 5 years, regional location, age since incorporation, and whether or not the firm uses Blueprinty‚Äôs software. The marketing team would like to use this data to make the claim that firms using Blueprinty‚Äôs software are more successful in getting their patent applications approved.\n\n\n\ntodo: Read in data. First, we can read in the data and do some exploratory analysis.\n\nimport pandas as pd\n\ndf1 = pd.read_csv('blueprinty.csv')\ndf1.head()\n\n\n\n\n\n\n\n\npatents\nregion\nage\niscustomer\n\n\n\n\n0\n0\nMidwest\n32.5\n0\n\n\n1\n3\nSouthwest\n37.5\n0\n\n\n2\n4\nNorthwest\n27.0\n1\n\n\n3\n3\nNortheast\n24.5\n0\n\n\n4\n3\nSouthwest\n37.0\n0\n\n\n\n\n\n\n\nLet‚Äôs compare histograms and means of number of patents by customer status. todo: Compare histograms and means of number of patents by customer status. What do you observe?\n\nimport matplotlib.pyplot as plt\n\n# Create two histograms side by side\nplt.figure(figsize=(12, 5))\n\n# Histogram for non-customers\nplt.subplot(1, 2, 1)\nplt.hist(df1[df1['iscustomer'] == 0]['patents'], bins=30, alpha=0.7)\nplt.title('Non-Customers: Number of Patents')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\n# Histogram for customers\nplt.subplot(1, 2, 2)\nplt.hist(df1[df1['iscustomer'] == 1]['patents'], bins=30, alpha=0.7, color='orange')\nplt.title('Customers: Number of Patents')\nplt.xlabel('Number of Patents')\nplt.ylabel('Frequency')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nHistograms indicate somewhat similar results. Let‚Äôs compare means to test for statistical significance.\n\nfrom scipy.stats import ttest_ind\n\n# Separate the groups\npatents_customers = df1[df1['iscustomer'] == 1]['patents']\npatents_non_customers = df1[df1['iscustomer'] == 0]['patents']\n\n# Calculate means\nmean_customers = patents_customers.mean()\nmean_non_customers = patents_non_customers.mean()\n\n# Perform the t-test\nt_stat, p_value = ttest_ind(patents_customers, patents_non_customers, equal_var=False)\n\n# Print results\nprint(f\"Mean patents (customers): {mean_customers:.2f}\")\nprint(f\"Mean patents (non-customers): {mean_non_customers:.2f}\")\nprint(f\"T-statistic: {t_stat:.3f}\")\nprint(f\"P-value: {p_value:.3f}\")\n\nMean patents (customers): 4.13\nMean patents (non-customers): 3.47\nT-statistic: 4.873\nP-value: 0.000\n\n\nBased on our t-test results, we reject the null hypothesis that the means are equal.\nBlueprinty customers are not selected at random. It may be important to account for systematic differences in the age and regional location of customers vs non-customers.\ntodo: Compare regions and ages by customer status. What do you observe?\nLet‚Äôs compare age between the customer and non customer groups first.\n\nimport seaborn as sns\n\nplt.figure(figsize=(10, 5))\n\nsns.kdeplot(data=df1, x='age', hue='iscustomer', fill=True, common_norm=False, alpha=0.5)\nplt.title('Age Distribution by Customer Status')\nplt.xlabel('Age')\nplt.ylabel('Density')\nplt.legend(title='Is Customer', labels=['Non-Customer', 'Customer'])\nplt.show()\n\n\n\n\n\n\n\n\nThere appears to be a slight difference in age between customers and non customers. Let‚Äôs run a t-test to check.\n\n# Separate the age values\nage_customers = df1[df1['iscustomer'] == 1]['age']\nage_non_customers = df1[df1['iscustomer'] == 0]['age']\n\n# Calculate means\nmean_age_customers = age_customers.mean()\nmean_age_non_customers = age_non_customers.mean()\n\n# Perform the t-test\nt_stat_age, p_value_age = ttest_ind(age_customers, age_non_customers, equal_var=False)\n\n# Print results\nprint(f\"Mean age (customers): {mean_age_customers:.2f}\")\nprint(f\"Mean age (non-customers): {mean_age_non_customers:.2f}\")\nprint(f\"T-statistic (age): {t_stat_age:.3f}\")\nprint(f\"P-value (age): {p_value_age:.3f}\")\n\nMean age (customers): 26.90\nMean age (non-customers): 26.10\nT-statistic (age): 1.913\nP-value (age): 0.056\n\n\nWe fail to reject the null hypothesis, indicating no statistically significant difference in age between the customer and non customer groups. Now we repeat the process for region.\n\n# Create a count table (not normalized)\nregion_counts = pd.crosstab(df1['region'], df1['iscustomer'])\nregion_counts.columns = ['Non-Customers', 'Customers']\n\n# Plot grouped bar chart\nregion_counts.plot(kind='bar', figsize=(10, 6))\nplt.title('Number of Customers and Non-Customers by Region')\nplt.xlabel('Region')\nplt.ylabel('Count')\nplt.xticks(rotation=45)\nplt.legend(title='Customer Status')\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\nIt appears based on the chart that there are some differences in the proportions of customers vs.¬†non customers in different regions. We‚Äôll run a chi-squared test to check this.\n\nfrom scipy.stats import chi2_contingency\n\n# Crosstab: region vs customer status\nregion_table = pd.crosstab(df1['region'], df1['iscustomer'])\n\n# Chi-squared test\nchi2_stat, p_value_region, dof, expected = chi2_contingency(region_table)\n\nprint(\"Chi-squared Statistic:\", round(chi2_stat, 2))\nprint(\"Degrees of Freedom:\", dof)\nprint(\"P-value:\", round(p_value_region, 4))\n\nChi-squared Statistic: 233.63\nDegrees of Freedom: 4\nP-value: 0.0\n\n\nBased on the low p-value, we can assume there is a statistically significant relationship between region and customer status. Accordingly, the distribution of customers across regions is not random, as some are more or less likely to have customers.\n\n\n\nSince our outcome variable of interest can only be small integer values per a set unit of time, we can use a Poisson density to model the number of patents awarded to each engineering firm over the last 5 years. We start by estimating a simple Poisson model via Maximum Likelihood.\ntodo: Write down mathematically the likelihood for \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nLet‚Äôs mathematically write the likelihood for_ \\(Y \\sim \\text{Poisson}(\\lambda)\\). Note that \\(f(Y|\\lambda) = e^{-\\lambda}\\lambda^Y/Y!\\).\nThe likelihood for all observations is:\n\\(L(\\lambda \\mid Y) = \\prod_{i=1}^n \\frac{e^{-\\lambda} \\lambda^{Y_i}}{Y_i!}\\)\nThe log-likelihood is:\n\\(\\ell(\\lambda \\mid Y) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\\)\ntodo: Code the likelihood (or log-likelihood) function for the Poisson model. This is a function of lambda and Y. For example: Now let‚Äôs write the log-likelihood function for the Poisson model as a function of lambda and Y.\n\nimport numpy as np\nfrom scipy.special import gammaln  # log(Y!) = gammaln(Y + 1)\n\ndef poisson_loglikelihood(lambd, Y):\n    \"\"\"\n    Compute the log-likelihood of a Poisson model given lambda and observed data Y.\n\n    Parameters:\n    - lambd: float, the Poisson rate parameter (must be &gt; 0)\n    - Y: array-like, observed count data\n\n    Returns:\n    - log-likelihood value\n    \"\"\"\n    if lambd &lt;= 0:\n        return -np.inf  # log-likelihood is undefined for lambda &lt;= 0\n    return np.sum(-lambd + Y * np.log(lambd) - gammaln(Y + 1))\n\ntodo: Use your function to plot lambda on the horizontal axis and the likelihood (or log-likelihood) on the vertical axis for a range of lambdas (use the observed number of patents as the input for Y).\nNow, let‚Äôs use the function to plot lambda on the horizontal axis and the log-likelihood on the vertical axis for a range of lambdas.\n\n# Get observed patent data\nY_obs = df1['patents'].values\n\n# Define a range of lambda values to evaluate\nlambda_vals = np.linspace(0.1, 20, 200)\n\n# Compute the log-likelihood for each lambda\nloglik_vals = [poisson_loglikelihood(l, Y_obs) for l in lambda_vals]\n\n# Plot the log-likelihood curve\nplt.figure(figsize=(8, 5))\nplt.plot(lambda_vals, loglik_vals, color='blue', lw=2)\nplt.title('Log-Likelihood of Poisson Model vs. Lambda')\nplt.xlabel(r'$\\lambda$')\nplt.ylabel('Log-Likelihood')\nplt.grid(True)\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\ntodo: If you‚Äôre feeling mathematical, take the first derivative of your likelihood or log-likelihood, set it equal to zero and solve for lambda. You will find lambda_mle is Ybar, which ‚Äúfeels right‚Äù because the mean of a Poisson distribution is lambda.\nWe start with the log-likelihood:\n\\[\n\\ell(\\lambda \\mid Y) = \\sum_{i=1}^n \\left( -\\lambda + Y_i \\log \\lambda - \\log(Y_i!) \\right)\n\\]\nTaking the derivative:\n\\[\n\\frac{d\\ell}{d\\lambda} = \\sum_{i=1}^n \\left( -1 + \\frac{Y_i}{\\lambda} \\right)\n= -n + \\frac{1}{\\lambda} \\sum_{i=1}^n Y_i\n\\]\nSet this equal to zero and solve:\n\\[\n-n + \\frac{1}{\\lambda} \\sum Y_i = 0 \\Rightarrow \\lambda = \\frac{1}{n} \\sum Y_i = \\bar{Y}\n\\]\nTherefore, the MLE of \\(\\lambda\\) is the sample mean \\(\\bar{Y}\\).\ntodo: Find the MLE by optimizing your likelihood function with optim() in R or sp.optimize() in Python.\nLet‚Äôs find the MLE by optimizing the likelihood function.\n\nfrom scipy.optimize import minimize_scalar\n\n# Reuse observed data\nY_obs = df1['patents'].values\n\n# Define negative log-likelihood function\ndef neg_loglik_poisson(lambd):\n    return -poisson_loglikelihood(lambd, Y_obs)\n\n# Use minimize_scalar to find the lambda that minimizes negative log-likelihood\nresult = minimize_scalar(neg_loglik_poisson, bounds=(0.01, 50), method='bounded')\n\n# Extract MLE\nlambda_mle_numerical = result.x\nloglik_at_mle = -result.fun\n\nprint(f\"MLE (Numerical): {lambda_mle_numerical:.4f}\")\nprint(f\"Log-Likelihood at MLE: {loglik_at_mle:.4f}\")\n\n# Compare to analytic MLE\nprint(f\"MLE (Analytic Mean): {np.mean(Y_obs):.4f}\")\n\nMLE (Numerical): 3.6847\nLog-Likelihood at MLE: -3367.6838\nMLE (Analytic Mean): 3.6847\n\n\nBoth methods agree that the best fitting Poisson model indicates that firms receive, on average, 3.68 patents every five years.\n\n\n\nNext, we extend our simple Poisson model to a Poisson Regression Model such that \\(Y_i = \\text{Poisson}(\\lambda_i)\\) where \\(\\lambda_i = \\exp(X_i'\\beta)\\). The interpretation is that the success rate of patent awards is not constant across all firms (\\(\\lambda\\)) but rather is a function of firm characteristics \\(X_i\\). Specifically, we will use the covariates age, age squared, region, and whether the firm is a customer of Blueprinty.\ntodo: Update your likelihood or log-likelihood function with an additional argument to take in a covariate matrix X. Also change the parameter of the model from lambda to the beta vector. In this model, lambda must be a positive number, so we choose the inverse link function g_inv() to be exp() so that \\(\\lambda_i = e^{X_i'\\beta}\\). For example:\nLet‚Äôs define our updated regression function.\n\ndef poisson_regression_loglikelihood(beta, Y, X):\n    \"\"\"\n    Log-likelihood for Poisson regression.\n\n    Parameters:\n    - beta: (p,) vector of coefficients\n    - Y: (n,) vector of observed counts\n    - X: (n, p) matrix of covariates\n\n    Returns:\n    - scalar log-likelihood value\n    \"\"\"\n    beta = np.asarray(beta, dtype=np.float64)  # ensure correct type\n    X = np.asarray(X, dtype=np.float64)        # ensure matrix format\n    Xb = np.dot(X, beta)                       # matrix multiplication\n    lambdas = np.exp(Xb)                       # element-wise exponential\n    return np.sum(-lambdas + Y * Xb - gammaln(Y + 1))\n\nNow, let‚Äôs create the covariate matrix X.\n\nimport patsy  # optional, but can simplify dummy creation\n\n# Create a copy of the data to work with\ndf = df1.copy()\n\n# Create new variables\n# Rescale age and age_squared\ndf['age'] = df['age'] / 10\ndf['age_squared'] = df['age'] ** 2\n\n# One-hot encode region, dropping one to avoid multicollinearity\nregion_dummies = pd.get_dummies(df['region'], drop_first=True)\n\n# Combine into one design matrix\nX = pd.concat([\n    pd.Series(1, index=df.index, name='intercept'),\n    df[['age', 'age_squared', 'iscustomer']],\n    pd.get_dummies(df['region'], drop_first=True)\n], axis=1)\n\nY = df['patents'].values\nX_mat = X.values  # for optimization input only\n\n# Column names\ncolumn_names = X.columns\n\ntodo: Use your function along with R‚Äôs optim() or Python‚Äôs sp.optimize() to find the MLE vector and the Hessian of the Poisson model with covariates. Specifically, the first column of X should be all 1‚Äôs to enable a constant term in the model, and the subsequent columns should be age, age squared, binary variables for all but one of the regions, and the binary customer variable. Use the Hessian to find standard errors of the beta parameter estimates and present a table of coefficients and standard errors.\nLet‚Äôs now optimize to find the MLE vector and the Hessian of the Poisson model with covariates.\n\nfrom scipy.optimize import minimize\n\nX_mat = X.to_numpy().astype(np.float64)  # make sure X is a NumPy array\nY_vec = Y.astype(np.float64)             # make sure Y is a NumPy array\ninit_beta = np.zeros(X_mat.shape[1])     # starting guess for beta (all 0s)\n\n# Define the negative log-likelihood function for use in optimizer\nneg_loglik = lambda b: -poisson_regression_loglikelihood(b, Y_vec, X_mat)\n\n# Optimize\nresult = minimize(neg_loglik, init_beta, method='BFGS')\n\nLet‚Äôs now extract the results.\n\n# Extract estimated coefficients and standard errors\nbeta_hat = result.x\nvcov_beta = result.hess_inv\nstandard_errors = np.sqrt(np.diag(vcov_beta))\n\n# Show results in a table\nsummary_table = pd.DataFrame({\n    'Coefficient': beta_hat,\n    'Std. Error': standard_errors\n}, index=X.columns)\n\nsummary_table\n\n\n\n\n\n\n\n\nCoefficient\nStd. Error\n\n\n\n\nintercept\n-0.508925\n0.185670\n\n\nage\n1.486199\n0.139210\n\n\nage_squared\n-0.297048\n0.025840\n\n\niscustomer\n0.207591\n0.032190\n\n\nNortheast\n0.029170\n0.046083\n\n\nNorthwest\n-0.017574\n0.055659\n\n\nSouth\n0.056562\n0.054619\n\n\nSouthwest\n0.050576\n0.048116\n\n\n\n\n\n\n\nThe Poisson regression estimates how the expected number of patents awarded to a firm varies with its characteristics. To improve numerical stability during optimization, the age variable was scaled by a factor of 10 (i.e., a one-unit change in age represents a 10-year difference).\nThe coefficient for age is 1.49, and for age_squared is ‚àí0.30, indicating a non-linear relationship: as firms age, their expected number of patents initially increases, but the rate of increase slows and eventually declines with age.\nThe coefficient on iscustomer is 0.208, meaning that, holding all else equal, firms that use Blueprinty‚Äôs software have a 23% higher expected patent count compared to non-customers. See.\nRegional effects appear minimal, with all region dummy coefficients close to zero and standard errors indicating low statistical significance relative to the reference region.\ntodo: Check your results using R‚Äôs glm() function or Python sm.GLM() function.\nNow let‚Äôs compare results against the statsmodels ‚Äòsm.GLM()‚Äô function.\n\nimport statsmodels.api as sm\n\n# Recreate X_sm and ensure it's numeric\nX_sm = sm.add_constant(X.drop(columns='intercept'), has_constant='add')\nX_sm = X_sm.astype(float)  # &lt;== This line prevents the object dtype error\n\n# Also ensure Y is numeric\nY_numeric = Y.astype(float)\n\n# Fit GLM model\nglm_model = sm.GLM(Y_numeric, X_sm, family=sm.families.Poisson())\nglm_results = glm_model.fit()\n\n# Display summary\nprint(glm_results.summary())\n\n                 Generalized Linear Model Regression Results                  \n==============================================================================\nDep. Variable:                      y   No. Observations:                 1500\nModel:                            GLM   Df Residuals:                     1492\nModel Family:                 Poisson   Df Model:                            7\nLink Function:                    Log   Scale:                          1.0000\nMethod:                          IRLS   Log-Likelihood:                -3258.1\nDate:                Sun, 04 May 2025   Deviance:                       2143.3\nTime:                        16:43:58   Pearson chi2:                 2.07e+03\nNo. Iterations:                     5   Pseudo R-squ. (CS):             0.1360\nCovariance Type:            nonrobust                                         \n===============================================================================\n                  coef    std err          z      P&gt;|z|      [0.025      0.975]\n-------------------------------------------------------------------------------\nconst          -0.5089      0.183     -2.778      0.005      -0.868      -0.150\nage             1.4862      0.139     10.716      0.000       1.214       1.758\nage_squared    -0.2970      0.026    -11.513      0.000      -0.348      -0.246\niscustomer      0.2076      0.031      6.719      0.000       0.147       0.268\nNortheast       0.0292      0.044      0.669      0.504      -0.056       0.115\nNorthwest      -0.0176      0.054     -0.327      0.744      -0.123       0.088\nSouth           0.0566      0.053      1.074      0.283      -0.047       0.160\nSouthwest       0.0506      0.047      1.072      0.284      -0.042       0.143\n===============================================================================\n\n\ntodo: Interpret the results.\nThe results closely matched those from the custom maximum likelihood estimation (MLE) approach, with all coefficients and standard errors agreeing to several decimal places. This confirms that our manually coded log-likelihood function and optimization routine are correctly specified.\ntodo: What do you conclude about the effect of Blueprinty‚Äôs software on patent success? Because the beta coefficients are not directly interpretable, it may help to create two fake datasets: X_0 and X_1 where X_0 is the X data but with iscustomer=0 for every observation and X_1 is the X data but with iscustomer=1 for every observation. Then, use X_0 and your fitted model to get the vector of predicted number of patents (y_pred_0) for every firm in the dataset, and use X_1 to get Y_pred_1 for every firm. Then subtract y_pred_1 minus y_pred_0 and take the average of that vector of differences."
  },
  {
    "objectID": "projects/hw2/index.html#airbnb-case-study",
    "href": "projects/hw2/index.html#airbnb-case-study",
    "title": "Poisson Regression Examples",
    "section": "AirBnB Case Study",
    "text": "AirBnB Case Study\n\nIntroduction\nAirBnB is a popular platform for booking short-term rentals. In March 2017, students Annika Awad, Evan Lebo, and Anna Linden scraped of 40,000 Airbnb listings from New York City. The data include the following variables:\n\n\n\n\n\n\nVariable Definitions\n\n\n\n\n\n- `id` = unique ID number for each unit\n- `last_scraped` = date when information scraped\n- `host_since` = date when host first listed the unit on Airbnb\n- `days` = `last_scraped` - `host_since` = number of days the unit has been listed\n- `room_type` = Entire home/apt., Private room, or Shared room\n- `bathrooms` = number of bathrooms\n- `bedrooms` = number of bedrooms\n- `price` = price per night (dollars)\n- `number_of_reviews` = number of reviews for the unit on Airbnb\n- `review_scores_cleanliness` = a cleanliness score from reviews (1-10)\n- `review_scores_location` = a \"quality of location\" score from reviews (1-10)\n- `review_scores_value` = a \"quality of value\" score from reviews (1-10)\n- `instant_bookable` = \"t\" if instantly bookable, \"f\" if not\n\n\n\ntodo: Assume the number of reviews is a good proxy for the number of bookings. Perform some exploratory data analysis to get a feel for the data, handle or drop observations with missing values on relevant variables, build one or more models (e.g., a poisson regression model for the number of bookings as proxied by the number of reviews), and interpret model coefficients to describe variation in the number of reviews as a function of the variables provided."
  }
]